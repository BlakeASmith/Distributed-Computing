

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Summary of Distributed Systems for Fun and Profit Chapter 4 &mdash; Distributed Computing Summer 2020 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Summary of Chapter 5" href="dsffap5.html" />
    <link rel="prev" title="Summary of The Chubby lock service for loosely-coupled distributed systems" href="chubby.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Distributed Computing Summer 2020
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="google_article.html">Google Article on Distributed Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_beyondelevennines_talk.html">Noes from AWS Beyond Eleven Nines Talk</a></li>
<li class="toctree-l1"><a class="reference internal" href="clock_exercise/clock_exercise.html">Clock Exercise</a></li>
<li class="toctree-l1"><a class="reference internal" href="grpc/grpc.html">Diggind in to the gRPC example code</a></li>
<li class="toctree-l1"><a class="reference internal" href="labs/lab2.html">Lab 2: A Simplified Distributed Map Reduce</a></li>
<li class="toctree-l1"><a class="reference internal" href="labs/lab3/lab3report.html">CSC Lab 3: Analysis of Map-Reduce Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="chubby.html">Summary of The Chubby lock service for loosely-coupled distributed systems</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Summary of Distributed Systems for Fun and Profit Chapter 4</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#questions">Questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#research">Research</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dsffap5.html">Summary of Chapter 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="project_critiques.html">Project Phase 1 Critiques</a></li>
<li class="toctree-l1"><a class="reference internal" href="cap_critiqe.html">Summary of A Critique of the CAP Theorem</a></li>
<li class="toctree-l1"><a class="reference internal" href="wc.html">Cumulative Wordcounts from 1452 pages on UsedVictoria.com</a></li>
<li class="toctree-l1"><a class="reference internal" href="kafka.html">Event Streaming: Lessons from Confluent-Cloud</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Distributed Computing Summer 2020</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Summary of Distributed Systems for Fun and Profit Chapter 4</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dsffap4.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="summary-of-distributed-systems-for-fun-and-profit-chapter-4">
<h1>Summary of Distributed Systems for Fun and Profit Chapter 4<a class="headerlink" href="#summary-of-distributed-systems-for-fun-and-profit-chapter-4" title="Permalink to this headline">¶</a></h1>
<p>See the full chapter here at <a class="reference external" href="http://book.mixu.net/distsys/single-page.html">http://book.mixu.net/distsys/single-page.html</a></p>
<p><strong>Chapter 4</strong> discusses the <strong>replication problem</strong> and various strategies for
dealing with it. These strategies are grouped into two major categories:</p>
<dl class="field-list simple">
<dt class="field-odd">Single Copy Systems</dt>
<dd class="field-odd"><p>prevent divergence by ensuring only a single copy of the
data is active at any given time. Ensure replicas are in agreement
such that when one fails, another can replace it without issue.</p>
</dd>
<dt class="field-even">Multi-Master Systems</dt>
<dd class="field-even"><p>risk divergence by maintaining multiple active copies of the data
at the same time. Availability will be improved, but at the cost of
preventing divergence</p>
</dd>
</dl>
<p>The author goes on to discuss <strong>Primary/Backup replication</strong>, <strong>Two Phase Commit</strong>, and <strong>Partition Tolerant
Consensus Algorithms</strong> such as <strong>Raft</strong>.</p>
<p><strong>Primary/Backup replication</strong> is the simplest of the bunch and comes in <em>syncronous</em> and <em>asyncronous</em> flavors.
In this replication scheme, all updates are perfomed at the primary (leader) data store. The updates are then
pushed to the backup (follower) replicas.</p>
<p>The following sequence diagrams show the Asyncronous and Syncronous versions of this scheme.</p>
  <pre>
  Sync Primary/Backup: 1 message per replica

  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |        |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'
Client            Primary            Backup1            Backup2
  │   write(DATA)    │                  │                  │
  │ ────────────────>│                  │                  │
  │                  │                  │                  │
  │           ╔══════╧══════╗           │                  │
  │           ║writes data ░║           │                  │
  │           ╚══════╤══════╝           │                  │
  │      return      │                  │                  │
  │ <────────────────│                  │                  │
  │                  │                  │                  │
  │                  │   wrtie(DATA)    │                  │
  │                  │─────────────────>│                  │
  │                  │                  │                  │
  │                  │            write(DATA)              │
  │                  │────────────────────────────────────>│
  │                  │                  │                  │
  │                  │             ╔════╧══════════════════╧════╗
  │                  │             ║writes data                ░║
Client            Primary          ╚════════════════════════════╝
  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |        |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'





  Sync Primary/Backup: 2 messages per replica

  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |        |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'
Client            Primary            Backup1            Backup2
  │   write(DATA)    │                  │                  │
  │ ────────────────>│                  │                  │
  │                  │                  │                  │
  │           ╔══════╧══════╗           │                  │
  │           ║writes data ░║           │                  │
  │           ╚══════╤══════╝           │                  │
  │                  │   wrtie(DATA)    │                  │
  │                  │─────────────────>│                  │
  │                  │                  │                  │
  │                  │            write(DATA)              │
  │                  │────────────────────────────────────>│
  │                  │                  │                  │
  │                  │             ╔════╧══════════════════╧════╗
  │                  │             ║writes data                ░║
  │                  │             ╚════╤══════════════════╤════╝
  │                  │       ACK        │                  │
  │                  │<─────────────────│                  │
  │                  │                  │                  │
  │                  │                ACK                  │
  │                  │<────────────────────────────────────│
  │                  │                  │                  │
  │      return      │                  │                  │
  │ <────────────────│                  │                  │
Client            Primary            Backup1            Backup2
  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |        |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'


  </pre><p>The next step up is <strong>Two Phase Commit</strong>. It works alot like <em>syncronous Primary/Backup</em> in the beginning.
The difference is that the replicas will not write to their “real” logs immediatley. Instead they will write to
a temporary (<em>write-ahead</em>) log. Each backup will then vote on whether to commit the entry or abort it. Once the votes
are received at the Primary, a decition will be made and the backups will be updated. Updating the diagram from before we get:</p>
  <pre>

                   2PC:4 messages per replica

  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |       |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'
Client            Primary            Backup1            Backup2
  │   write(DATA)    │                  │                  │
  │ ────────────────>│                  │                  │
  │                  │                  │                  │
  │     ╔════════════╧════════════╗     │                  │
  │     ║writes data to temp log ░║     │                  │
  │     ╚════════════╤════════════╝     │                  │
  │                  │   wrtie(DATA)    │                  │
  │                  │─────────────────>│                  │
  │                  │                  │                  │
  │                  │            write(DATA)              │
  │                  │────────────────────────────────────>│
  │                  │                  │                  │
  │                  │             ╔════╧══════════════════╧════╗
  │                  │             ║writes data to temp log    ░║
  │                  │             ╚════╤══════════════════╤════╝
  │                  │vote COMMIT/ABORT │                  │
  │                  │<─────────────────│                  │
  │                  │                  │                  │
  │                  │         vote COMMIT/ABORT           │
  │                  │<────────────────────────────────────│
  │                  │                  │                  │
  │        ╔═════════╧══════════╗       │                  │
  │        ║makes a decition   ░║       │                  │
  │        ║based on the votes  ║       │                  │
  │        ╚═════════╤══════════╝       │                  │
  │                  │  COMMIT/ABORT    │                  │
  │                  │─────────────────>│                  │
  │                  │                  │                  │
  │                  │            COMMIT/ABORT             │
  │                  │────────────────────────────────────>│
  │                  │                  │                  │
  │                  │         ╔════════╧══════════════════╧════════╗
  │                  │         ║writes to the "real" log or aborts ░║
  │                  │         ╚════════╤══════════════════╤════════╝
  │                  │       ACK        │                  │
  │                  │<─────────────────│                  │
  │                  │                  │                  │
  │                  │                ACK                  │
  │                  │<────────────────────────────────────│
  │                  │                  │                  │
  │      ╔═══════════╧═══════════╗      │                  │
  │      ║writes to the "real"  ░║      │                  │
  │      ║log or aborts          ║      │                  │
  │      ╚═══════════╤═══════════╝      │                  │
  │      return      │                  │                  │
  │ <────────────────│                  │                  │
Client            Primary            Backup1            Backup2
  ┌─┐             ,.-^^-._           ,.-^^-._           ,.-^^-._
  ║"│            |-.____.-|         |-.____.-|         |-.____.-|
  └┬┘            |        |         |        |         |        |
  ┌┼┐            |        |         |        |         |        |
   │             |        |         |        |         |        |
  ┌┴┐            '-.____.-'         '-.____.-'         '-.____.-'


  </pre><p>Finally, the autor discusses partion tolerant algorithms like <em>Raft</em> and <em>Paxos</em>. These algorthms
add partion tolerance to <em>2PC</em> by requiring agreement among only a <strong>majority</strong> of nodes (as apposed
to total consensus). By doing so, they ensure that only one (leader) replica is active during a partion
(as the smaller partition would not be able to reach a majority vote). Disagreements will may
prevent the algorithm from making progress, but single-copy consistency will not be violated.</p>
<div class="section" id="questions">
<h2>Questions<a class="headerlink" href="#questions" title="Permalink to this headline">¶</a></h2>
<p>After reading through this chapter the following questions come to mind:</p>
<ul class="simple">
<li><p>When is it sufficient to use 2PC, or even Primary/Backup, instead of an algroithm such as Raft or Paxos?</p></li>
<li><dl class="simple">
<dt>What are examples of <em>Multi-Master</em> style replication strategies?</dt><dd><ul>
<li><p>The author mentioned Mulit-Master systems, but did not go into any details or give expamples</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="research">
<h2>Research<a class="headerlink" href="#research" title="Permalink to this headline">¶</a></h2>
<p>Since it wasn’t really addressed in the artice, I did some reading on Multi-Master repliaction schemes from the following
sources:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multi-master_replication">https://en.wikipedia.org/wiki/Multi-master_replication</a></p></li>
<li><p><a class="reference external" href="https://dzone.com/articles/pros-and-cons-of-mysql-replication-types">https://dzone.com/articles/pros-and-cons-of-mysql-replication-types</a></p></li>
<li><p><a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster-replication-multi-master.html">https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster-replication-multi-master.html</a></p></li>
<li><p><a class="reference external" href="https://blogs.oracle.com/jsmyth/circular-replication-in-mysql">https://blogs.oracle.com/jsmyth/circular-replication-in-mysql</a></p></li>
</ol>
<p>Multi-Master systems themselves can come in a few configurations;</p>
<p>you can have <strong>Circular Replication</strong>, <strong>Master-Master Replication with N masters</strong>, and  <strong>Master Group Replication (MGR)</strong></p>
<dl class="field-list">
<dt class="field-odd">Circular Replication</dt>
<dd class="field-odd"><p>circular replication is exactly what it sounds like. Every node is a master, and every master replicates to exactly one
other master. So if there were 4 nodes in my cluster labeled A, B, C, D the replication would flow as</p>
<p>A -&gt; B -&gt; C -&gt; D -&gt; A</p>
<p>Then, a client could perform a write at any node, and it would be replicated to all others since they are all
connected in this circle.</p>
<p>There’s an obvious problem with this… If any one node goes down the circle breaks. This means that failure at one node
means failure of the entire system, making this less reliable than just having a single server. The benifit is <strong>write scalability</strong>, since
writes are able to be performed at any node.</p>
</dd>
<dt class="field-even">Master-Master Replication with N Masters</dt>
<dd class="field-even"><p>In this scheme we habe N masters and M followers. We get better write-scalability as we have more master nodes we can write too. Additionally the
Master nodes can be spaced out geographically to provide lower latencies in more places. The Masters can all replicate to eachother and the followers.
Writes are accepted at any Master node and replicated to all other nodes.</p>
</dd>
<dt class="field-odd">Master Group Replication</dt>
<dd class="field-odd"><p>In Master Group Replication, the set of all nodes is split into a number of groups. Then each group will have it’s own master and
leader election process within that group. Writes are accepted at any of the Master nodes, but the replication works a little
differently. Instead of the single Master (the one that received the write request) replicating the data across all nodes, It makes a
write request to all of the other Master nodes. Then each Master handles replicating the data to it’s own followers.</p>
</dd>
</dl>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dsffap5.html" class="btn btn-neutral float-right" title="Summary of Chapter 5" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="chubby.html" class="btn btn-neutral float-left" title="Summary of The Chubby lock service for loosely-coupled distributed systems" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Blake Smith

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>